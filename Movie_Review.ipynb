{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Movie_Review.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPcjL4cHvqKq3DBlp+/z0x4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "CG5sX-GV8hp6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "5709ee27-cb7e-4199-9be0-b3afabceadb8"
      },
      "source": [
        "from keras.datasets import imdb\n",
        "\n",
        "(train_data, train_labels),(test_data,test_labels) = imdb.load_data(num_words=10000) \n",
        "# num_words 매개변수는 훈련 데이터에서 가장 자주 나타나는 단어 1만개를 사용하겠다는 의미이다.\n",
        "# 적절한 크기의 벡터 데이터를 얻을 수 있음.\n",
        " "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/text-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jw4XB9Ye9Saf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c1c30058-09a4-44fc-d74f-3749aa15c382"
      },
      "source": [
        "train_data[0]"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1,\n",
              " 14,\n",
              " 22,\n",
              " 16,\n",
              " 43,\n",
              " 530,\n",
              " 973,\n",
              " 1622,\n",
              " 1385,\n",
              " 65,\n",
              " 458,\n",
              " 4468,\n",
              " 66,\n",
              " 3941,\n",
              " 4,\n",
              " 173,\n",
              " 36,\n",
              " 256,\n",
              " 5,\n",
              " 25,\n",
              " 100,\n",
              " 43,\n",
              " 838,\n",
              " 112,\n",
              " 50,\n",
              " 670,\n",
              " 2,\n",
              " 9,\n",
              " 35,\n",
              " 480,\n",
              " 284,\n",
              " 5,\n",
              " 150,\n",
              " 4,\n",
              " 172,\n",
              " 112,\n",
              " 167,\n",
              " 2,\n",
              " 336,\n",
              " 385,\n",
              " 39,\n",
              " 4,\n",
              " 172,\n",
              " 4536,\n",
              " 1111,\n",
              " 17,\n",
              " 546,\n",
              " 38,\n",
              " 13,\n",
              " 447,\n",
              " 4,\n",
              " 192,\n",
              " 50,\n",
              " 16,\n",
              " 6,\n",
              " 147,\n",
              " 2025,\n",
              " 19,\n",
              " 14,\n",
              " 22,\n",
              " 4,\n",
              " 1920,\n",
              " 4613,\n",
              " 469,\n",
              " 4,\n",
              " 22,\n",
              " 71,\n",
              " 87,\n",
              " 12,\n",
              " 16,\n",
              " 43,\n",
              " 530,\n",
              " 38,\n",
              " 76,\n",
              " 15,\n",
              " 13,\n",
              " 1247,\n",
              " 4,\n",
              " 22,\n",
              " 17,\n",
              " 515,\n",
              " 17,\n",
              " 12,\n",
              " 16,\n",
              " 626,\n",
              " 18,\n",
              " 2,\n",
              " 5,\n",
              " 62,\n",
              " 386,\n",
              " 12,\n",
              " 8,\n",
              " 316,\n",
              " 8,\n",
              " 106,\n",
              " 5,\n",
              " 4,\n",
              " 2223,\n",
              " 5244,\n",
              " 16,\n",
              " 480,\n",
              " 66,\n",
              " 3785,\n",
              " 33,\n",
              " 4,\n",
              " 130,\n",
              " 12,\n",
              " 16,\n",
              " 38,\n",
              " 619,\n",
              " 5,\n",
              " 25,\n",
              " 124,\n",
              " 51,\n",
              " 36,\n",
              " 135,\n",
              " 48,\n",
              " 25,\n",
              " 1415,\n",
              " 33,\n",
              " 6,\n",
              " 22,\n",
              " 12,\n",
              " 215,\n",
              " 28,\n",
              " 77,\n",
              " 52,\n",
              " 5,\n",
              " 14,\n",
              " 407,\n",
              " 16,\n",
              " 82,\n",
              " 2,\n",
              " 8,\n",
              " 4,\n",
              " 107,\n",
              " 117,\n",
              " 5952,\n",
              " 15,\n",
              " 256,\n",
              " 4,\n",
              " 2,\n",
              " 7,\n",
              " 3766,\n",
              " 5,\n",
              " 723,\n",
              " 36,\n",
              " 71,\n",
              " 43,\n",
              " 530,\n",
              " 476,\n",
              " 26,\n",
              " 400,\n",
              " 317,\n",
              " 46,\n",
              " 7,\n",
              " 4,\n",
              " 2,\n",
              " 1029,\n",
              " 13,\n",
              " 104,\n",
              " 88,\n",
              " 4,\n",
              " 381,\n",
              " 15,\n",
              " 297,\n",
              " 98,\n",
              " 32,\n",
              " 2071,\n",
              " 56,\n",
              " 26,\n",
              " 141,\n",
              " 6,\n",
              " 194,\n",
              " 7486,\n",
              " 18,\n",
              " 4,\n",
              " 226,\n",
              " 22,\n",
              " 21,\n",
              " 134,\n",
              " 476,\n",
              " 26,\n",
              " 480,\n",
              " 5,\n",
              " 144,\n",
              " 30,\n",
              " 5535,\n",
              " 18,\n",
              " 51,\n",
              " 36,\n",
              " 28,\n",
              " 224,\n",
              " 92,\n",
              " 25,\n",
              " 104,\n",
              " 4,\n",
              " 226,\n",
              " 65,\n",
              " 16,\n",
              " 38,\n",
              " 1334,\n",
              " 88,\n",
              " 12,\n",
              " 16,\n",
              " 283,\n",
              " 5,\n",
              " 16,\n",
              " 4472,\n",
              " 113,\n",
              " 103,\n",
              " 32,\n",
              " 15,\n",
              " 16,\n",
              " 5345,\n",
              " 19,\n",
              " 178,\n",
              " 32]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTVdsxdn9Y0q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "58c8643a-b8ae-47c4-bb1d-1931d993aa60"
      },
      "source": [
        "train_labels[0]\n",
        "# negative = 0 / positive = 1  "
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lh2Xu2Tz9ehZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1562b228-19de-49a1-e031-b5152d9287b7"
      },
      "source": [
        "max([max(sequence) for sequence in train_data])\n",
        "# index is 9,999 / num_words = 10,000"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9999"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Z8TOXbN998L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_index = imdb.get_word_index()\n",
        "reverse_word_index = dict(\n",
        "    [(value, key) for (key , value) in word_index.items()]\n",
        ")\n",
        "\n",
        "decoded_review = ' '.join(\n",
        "    [reverse_word_index.get(i-3,'?') for i in train_data[0]]\n",
        ")\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3RNgKjY3_JHg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0030880c-1224-45d8-facc-7b6045b718c9"
      },
      "source": [
        "import numpy as np \n",
        "\n",
        "def vectorize_sequences(sequences, dimension=10000):\n",
        "    results = np.zeros((len(sequences),dimension)) # all zero \n",
        "\n",
        "    for i, sequence in enumerate(sequences):\n",
        "        results[i,sequence] = 1\n",
        "    return results\n",
        "\n",
        "x_train = vectorize_sequences(train_data)\n",
        "# change train data to vector\n",
        "x_test = vectorize_sequences(test_data)\n",
        "# change test data to vector \n",
        "\n",
        "x_train[0]\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1., 1., ..., 0., 0., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1TZ-XaWAkQ5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = np.asarray(train_labels).astype('float32')\n",
        "y_test = np.asarray(test_labels).astype('float32')\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7JvdU93Bo2q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_val = x_train[:10000]\n",
        "partial_x_train = x_train[10000:]\n",
        "y_val = y_train[:10000]\n",
        "partial_y_train = y_train[10000:]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHoN_9rdA0ok",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "from keras import optimizers\n",
        "from keras import losses\n",
        "from keras import metrics \n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(16,activation='relu', input_shape=(10000,)))\n",
        "model.add(layers.Dense(16,activation='relu'))\n",
        "model.add(layers.Dense(1,activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer=optimizers.RMSprop(lr=0.001),\n",
        "              loss=losses.binary_crossentropy,\n",
        "              metrics=[metrics.binary_accuracy])"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhZi7iF0Cvph",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        },
        "outputId": "5cce14c4-4c10-4dd8-b020-4855d2829b43"
      },
      "source": [
        "history = model.fit(partial_x_train,\n",
        "                    partial_y_train,\n",
        "                    epochs= 20,\n",
        "                    batch_size = 512,\n",
        "                    validation_data = (x_val,y_val))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 15000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "15000/15000 [==============================] - 2s 120us/step - loss: 0.5243 - binary_accuracy: 0.7882 - val_loss: 0.4037 - val_binary_accuracy: 0.8689\n",
            "Epoch 2/20\n",
            "15000/15000 [==============================] - 1s 94us/step - loss: 0.3221 - binary_accuracy: 0.9015 - val_loss: 0.3162 - val_binary_accuracy: 0.8848\n",
            "Epoch 3/20\n",
            "15000/15000 [==============================] - 2s 101us/step - loss: 0.2348 - binary_accuracy: 0.9244 - val_loss: 0.3212 - val_binary_accuracy: 0.8692\n",
            "Epoch 4/20\n",
            "15000/15000 [==============================] - 1s 95us/step - loss: 0.1855 - binary_accuracy: 0.9412 - val_loss: 0.2746 - val_binary_accuracy: 0.8921\n",
            "Epoch 5/20\n",
            "15000/15000 [==============================] - 1s 93us/step - loss: 0.1518 - binary_accuracy: 0.9511 - val_loss: 0.2820 - val_binary_accuracy: 0.8885\n",
            "Epoch 6/20\n",
            "15000/15000 [==============================] - 1s 97us/step - loss: 0.1217 - binary_accuracy: 0.9639 - val_loss: 0.3554 - val_binary_accuracy: 0.8629\n",
            "Epoch 7/20\n",
            "15000/15000 [==============================] - 1s 93us/step - loss: 0.1047 - binary_accuracy: 0.9679 - val_loss: 0.3042 - val_binary_accuracy: 0.8836\n",
            "Epoch 8/20\n",
            "15000/15000 [==============================] - 1s 95us/step - loss: 0.0859 - binary_accuracy: 0.9759 - val_loss: 0.3243 - val_binary_accuracy: 0.8814\n",
            "Epoch 9/20\n",
            "15000/15000 [==============================] - 1s 93us/step - loss: 0.0711 - binary_accuracy: 0.9805 - val_loss: 0.3532 - val_binary_accuracy: 0.8786\n",
            "Epoch 10/20\n",
            "15000/15000 [==============================] - 1s 93us/step - loss: 0.0590 - binary_accuracy: 0.9851 - val_loss: 0.3687 - val_binary_accuracy: 0.8803\n",
            "Epoch 11/20\n",
            "15000/15000 [==============================] - 1s 95us/step - loss: 0.0474 - binary_accuracy: 0.9885 - val_loss: 0.4427 - val_binary_accuracy: 0.8652\n",
            "Epoch 12/20\n",
            "15000/15000 [==============================] - 1s 94us/step - loss: 0.0386 - binary_accuracy: 0.9905 - val_loss: 0.4495 - val_binary_accuracy: 0.8715\n",
            "Epoch 13/20\n",
            "15000/15000 [==============================] - 1s 94us/step - loss: 0.0307 - binary_accuracy: 0.9935 - val_loss: 0.4968 - val_binary_accuracy: 0.8657\n",
            "Epoch 14/20\n",
            "15000/15000 [==============================] - 1s 93us/step - loss: 0.0254 - binary_accuracy: 0.9953 - val_loss: 0.4830 - val_binary_accuracy: 0.8720\n",
            "Epoch 15/20\n",
            "15000/15000 [==============================] - 1s 93us/step - loss: 0.0217 - binary_accuracy: 0.9962 - val_loss: 0.5159 - val_binary_accuracy: 0.8723\n",
            "Epoch 16/20\n",
            "15000/15000 [==============================] - 1s 94us/step - loss: 0.0154 - binary_accuracy: 0.9984 - val_loss: 0.5482 - val_binary_accuracy: 0.8691\n",
            "Epoch 17/20\n",
            "15000/15000 [==============================] - 1s 96us/step - loss: 0.0128 - binary_accuracy: 0.9987 - val_loss: 0.6332 - val_binary_accuracy: 0.8598\n",
            "Epoch 18/20\n",
            "15000/15000 [==============================] - 1s 94us/step - loss: 0.0101 - binary_accuracy: 0.9995 - val_loss: 0.6181 - val_binary_accuracy: 0.8680\n",
            "Epoch 19/20\n",
            "15000/15000 [==============================] - 1s 95us/step - loss: 0.0092 - binary_accuracy: 0.9984 - val_loss: 0.6526 - val_binary_accuracy: 0.8661\n",
            "Epoch 20/20\n",
            "15000/15000 [==============================] - 1s 95us/step - loss: 0.0049 - binary_accuracy: 0.9998 - val_loss: 0.7784 - val_binary_accuracy: 0.8540\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CEs3WHxvC8vI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history_dict = history.history"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6175vJ4DBMe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "de56b8ac-3bf5-45de-e376-70b7637579a8"
      },
      "source": [
        "history_dict.keys()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['val_loss', 'val_binary_accuracy', 'loss', 'binary_accuracy'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-P6JEUVuDVo4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# add graph / add prediction "
      ],
      "execution_count": 17,
      "outputs": []
    }
  ]
}